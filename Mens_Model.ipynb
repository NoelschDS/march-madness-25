{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "import patsy as pt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTeams = pd.read_csv('MTeams.csv')\n",
    "MSeasons = pd.read_csv('MSeasons.csv')\n",
    "MNCAATourneySeeds = pd.read_csv('MNCAATourneySeeds.csv')\n",
    "MRegularSeasonCompactResults = pd.read_csv('MRegularSeasonCompactResults.csv')\n",
    "MRegularSeasonDetailedResults = pd.read_csv('MRegularSeasonDetailedResults.csv') \n",
    "MNCAATourneyCompactResults = pd.read_csv('MNCAATourneyCompactResults.csv')\n",
    "MNCAATourneyDetailedResults = pd.read_csv('MNCAATourneyDetailedResults.csv')\n",
    "SampleSubmissionStage1 = pd.read_csv('SampleSubmissionStage1.csv')\n",
    "SampleSubmissionStage2 = pd.read_csv('SampleSubmissionStage2.csv')\n",
    "MMasseyOrdinals = pd.read_csv('MMasseyOrdinals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSubmissionStage1['Season'] = SampleSubmissionStage1['ID'].apply(lambda x: int(x.split('_')[0]))\n",
    "SampleSubmissionStage1['Team1'] = SampleSubmissionStage1['ID'].apply(lambda x: int(x.split('_')[1]))\n",
    "SampleSubmissionStage1['Team2'] = SampleSubmissionStage1['ID'].apply(lambda x: int(x.split('_')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_season_data(year, teams, data, rankings, template, details):\n",
    "    teams_lst = teams[(teams['FirstD1Season'] <= year) & (teams['LastD1Season'] >= year)]\n",
    "    results_data = data[data['Season'] == year]\n",
    "    rankings_data = rankings[rankings['Season'] == year]\n",
    "    sample_data = template[template['Season'] == year]\n",
    "    detailed_data = details[details['Season'] == year]\n",
    "    return teams_lst, results_data, rankings_data, sample_data, detailed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_21, results_21, rankings_21, sample_21, detailed_21 = regular_season_data(2021, MTeams, MRegularSeasonCompactResults, MMasseyOrdinals, SampleSubmissionStage1, MRegularSeasonDetailedResults)\n",
    "teams_22, results_22, rankings_22, sample_22, detailed_22 = regular_season_data(2022, MTeams, MRegularSeasonCompactResults, MMasseyOrdinals, SampleSubmissionStage1, MRegularSeasonDetailedResults)\n",
    "teams_23, results_23, rankings_23, sample_23, detailed_23 = regular_season_data(2023, MTeams, MRegularSeasonCompactResults, MMasseyOrdinals, SampleSubmissionStage1, MRegularSeasonDetailedResults)\n",
    "teams_24, results_24, rankings_24, sample_24, detailed_24 = regular_season_data(2024, MTeams, MRegularSeasonCompactResults, MMasseyOrdinals, SampleSubmissionStage1, MRegularSeasonDetailedResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Functions for Key Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_wins(Team1, results):\n",
    "    Team1_wins = 0\n",
    "    for index, row in results.iterrows():\n",
    "        if row['WTeamID'] == Team1:\n",
    "            Team1_wins += 1\n",
    "    return Team1_wins\n",
    "\n",
    "def avg_score_difference(Team1, results):\n",
    "    Team1_score_difference = 0\n",
    "    games = 0\n",
    "    for index, row in results.iterrows():\n",
    "        if row['WTeamID'] == Team1:\n",
    "            Team1_score_difference += row['WScore'] - row['LScore']\n",
    "            games += 1\n",
    "        if row['LTeamID'] == Team1:\n",
    "            Team1_score_difference += row['LScore'] - row['WScore']\n",
    "            games += 1\n",
    "    return Team1_score_difference/games if games != 0 else 0\n",
    "\n",
    "\n",
    "def weighted_avg_ranking(Team1, ranking_system, rankings_data):\n",
    "    # Filter data once\n",
    "    team_data = rankings_data[(rankings_data['TeamID'] == Team1) &\n",
    "                               (rankings_data['SystemName'] == ranking_system)]\n",
    "    \n",
    "    if team_data.empty:\n",
    "        return 0  # No data available    \n",
    "    # Get unique ranking days\n",
    "    unique_days = team_data['RankingDayNum'].unique()\n",
    "    total_days = len(unique_days)\n",
    "    \n",
    "    # Initialize weights\n",
    "    weights = range(total_days, 0, -1)\n",
    "    \n",
    "    # If there are fewer team_data rows than days, we need to adjust\n",
    "    if len(team_data) < total_days:\n",
    "        weights = weights[:len(team_data)]\n",
    "    \n",
    "    # Calculate weighted average\n",
    "    weighted_sum = sum(row.OrdinalRank * weight for row, weight in tqdm(zip(team_data.itertuples(), weights), total=len(weights)))\n",
    "    total_weight = sum(weights)\n",
    "    \n",
    "    return weighted_sum / total_weight if total_weight > 0 else 0\n",
    "\n",
    "def team_stats_differences(Team1, data):\n",
    "    Team1_FG_PCT = 0\n",
    "    Team1_FG3_PCT = 0\n",
    "    Team1_FT_PCT = 0\n",
    "    Team1_REB = 0\n",
    "    Team1_AST = 0\n",
    "    Team1_TO = 0\n",
    "    Team1_STL = 0\n",
    "    Team1_BLK = 0\n",
    "    Team1_PF = 0\n",
    "    games = 0\n",
    "    for index, row in data.iterrows():\n",
    "        if row['WTeamID'] == Team1:\n",
    "            Team1_FG_PCT += (row['WFGM'] / row['WFGA'] if row['WFGA'] != 0 else 0) - (row['LFGM'] / row['LFGA'] if row['LFGA'] != 0 else 0)\n",
    "            Team1_FG3_PCT += (row['WFGM3'] / row['WFGA3'] if row['WFGA3'] != 0 else 0) - (row['LFGM3'] / row['LFGA3'] if row['LFGA3'] != 0 else 0)\n",
    "            Team1_FT_PCT += (row['WFTM'] / row['WFTA'] if row['WFTA'] != 0 else 0) - (row['LFTM'] / row['LFTA'] if row['LFTA'] != 0 else 0)\n",
    "            Team1_REB += (row['WOR'] + row['WDR']) - (row['LOR'] + row['LDR'])\n",
    "            Team1_AST += row['WAst'] - row['LAst']\n",
    "            Team1_TO += row['WTO'] - row['LTO']\n",
    "            Team1_STL += row['WStl'] - row['LStl']\n",
    "            Team1_BLK += row['WBlk'] - row['LBlk']\n",
    "            Team1_PF += row['WPF'] - row['LPF']\n",
    "            games += 1\n",
    "        if row['LTeamID'] == Team1:\n",
    "            Team1_FG_PCT += (row['LFGM'] / row['LFGA'] if row['LFGA'] != 0 else 0) - (row['WFGM'] / row['WFGA'] if row['WFGA'] != 0 else 0)\n",
    "            Team1_FG3_PCT += (row['LFGM3'] / row['LFGA3'] if row['LFGA3'] != 0 else 0) - (row['WFGM3'] / row['WFGA3'] if row['WFGA3'] != 0 else 0)\n",
    "            Team1_FT_PCT += (row['LFTM'] / row['LFTA'] if row['LFTA'] != 0 else 0) - (row['WFTM'] / row['WFTA'] if row['WFTA'] != 0 else 0)\n",
    "            Team1_REB += (row['LOR'] + row['LDR']) - (row['WOR'] + row['WDR'])\n",
    "            Team1_AST += row['LAst'] - row['WAst']\n",
    "            Team1_TO += row['LTO'] - row['WTO']\n",
    "            Team1_STL += row['LStl'] - row['WStl']\n",
    "            Team1_BLK += row['LBlk'] - row['WBlk']\n",
    "            Team1_PF += row['LPF'] - row['WPF']\n",
    "            games += 1\n",
    "    return (Team1_FG_PCT/games if games != 0 else 0, \n",
    "            Team1_FG3_PCT/games if games != 0 else 0, \n",
    "            Team1_FT_PCT/games if games != 0 else 0, \n",
    "            Team1_REB/games if games != 0 else 0, \n",
    "            Team1_AST/games if games != 0 else 0, \n",
    "            Team1_TO/games if games != 0 else 0, \n",
    "            Team1_STL/games if games != 0 else 0, \n",
    "            Team1_BLK/games if games != 0 else 0, \n",
    "            Team1_PF/games if games != 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\520916570.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_21['Wins'] = teams_21['TeamID'].apply(lambda x: record_wins(x, results_21))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\520916570.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_22['Wins'] = teams_22['TeamID'].apply(lambda x: record_wins(x, results_22))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\520916570.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_23['Wins'] = teams_23['TeamID'].apply(lambda x: record_wins(x, results_23))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\520916570.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_24['Wins'] = teams_24['TeamID'].apply(lambda x: record_wins(x, results_24))\n"
     ]
    }
   ],
   "source": [
    "teams_21['Wins'] = teams_21['TeamID'].apply(lambda x: record_wins(x, results_21))\n",
    "teams_22['Wins'] = teams_22['TeamID'].apply(lambda x: record_wins(x, results_22))\n",
    "teams_23['Wins'] = teams_23['TeamID'].apply(lambda x: record_wins(x, results_23))\n",
    "teams_24['Wins'] = teams_24['TeamID'].apply(lambda x: record_wins(x, results_24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\4014827976.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_21['AvgScoreDifference'] = teams_21['TeamID'].apply(lambda x: avg_score_difference(x, results_21))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\4014827976.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_22['AvgScoreDifference'] = teams_22['TeamID'].apply(lambda x: avg_score_difference(x, results_22))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\4014827976.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_23['AvgScoreDifference'] = teams_23['TeamID'].apply(lambda x: avg_score_difference(x, results_23))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\4014827976.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_24['AvgScoreDifference'] = teams_24['TeamID'].apply(lambda x: avg_score_difference(x, results_24))\n"
     ]
    }
   ],
   "source": [
    "teams_21['AvgScoreDifference'] = teams_21['TeamID'].apply(lambda x: avg_score_difference(x, results_21))\n",
    "teams_22['AvgScoreDifference'] = teams_22['TeamID'].apply(lambda x: avg_score_difference(x, results_22))\n",
    "teams_23['AvgScoreDifference'] = teams_23['TeamID'].apply(lambda x: avg_score_difference(x, results_23))\n",
    "teams_24['AvgScoreDifference'] = teams_24['TeamID'].apply(lambda x: avg_score_difference(x, results_24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\2737721744.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_21['POM_avg'] = teams_21['TeamID'].apply(lambda x: avg_score_difference(x, results_21))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\2737721744.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_22['POM_avg'] = teams_22['TeamID'].apply(lambda x: avg_score_difference(x, results_22))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\2737721744.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_23['POM_avg'] = teams_23['TeamID'].apply(lambda x: avg_score_difference(x, results_23))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\2737721744.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_24['POM_avg'] = teams_24['TeamID'].apply(lambda x: avg_score_difference(x, results_24))\n"
     ]
    }
   ],
   "source": [
    "teams_21['POM_avg'] = teams_21['TeamID'].apply(lambda x: avg_score_difference(x, results_21))\n",
    "teams_22['POM_avg'] = teams_22['TeamID'].apply(lambda x: avg_score_difference(x, results_22))\n",
    "teams_23['POM_avg'] = teams_23['TeamID'].apply(lambda x: avg_score_difference(x, results_23))\n",
    "teams_24['POM_avg'] = teams_24['TeamID'].apply(lambda x: avg_score_difference(x, results_24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = teams_21['TeamID'].apply(lambda x: team_stats_differences(x, detailed_21))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "teams_21 = pd.concat([teams_21, team_stats_df], axis=1)\n",
    "\n",
    "team_stats = teams_22['TeamID'].apply(lambda x: team_stats_differences(x, detailed_22))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "teams_22 = pd.concat([teams_22, team_stats_df], axis=1)\n",
    "\n",
    "team_stats = teams_23['TeamID'].apply(lambda x: team_stats_differences(x, detailed_23))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "teams_23 = pd.concat([teams_23, team_stats_df], axis=1)\n",
    "\n",
    "team_stats = teams_24['TeamID'].apply(lambda x: team_stats_differences(x, detailed_24))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "teams_24 = pd.concat([teams_24, team_stats_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sample_21 with teams_21 for Team1 & Team2 details\n",
    "merged_sample_21 = sample_21.merge(teams_21, left_on='Team1', right_on='TeamID', suffixes=('', '_Team1'))\n",
    "merged_sample_21 = merged_sample_21.merge(teams_21, left_on='Team2', right_on='TeamID', suffixes=('_Team1', '_Team2'))\n",
    "merged_sample_21 = merged_sample_21.drop(columns=['TeamID_Team1', 'TeamID_Team2'])\n",
    "\n",
    "# Merge sample_22 with teams_22 for Team1 & Team2 details\n",
    "merged_sample_22 = sample_22.merge(teams_22, left_on='Team1', right_on='TeamID', suffixes=('', '_Team1'))\n",
    "merged_sample_22 = merged_sample_22.merge(teams_22, left_on='Team2', right_on='TeamID', suffixes=('_Team1', '_Team2'))\n",
    "merged_sample_22 = merged_sample_22.drop(columns=['TeamID_Team1', 'TeamID_Team2'])\n",
    "\n",
    "# Merge sample_23 with teams_23 for Team1 & Team2 details\n",
    "merged_sample_23 = sample_23.merge(teams_23, left_on='Team1', right_on='TeamID', suffixes=('', '_Team1'))\n",
    "merged_sample_23 = merged_sample_23.merge(teams_23, left_on='Team2', right_on='TeamID', suffixes=('_Team1', '_Team2'))\n",
    "merged_sample_23 = merged_sample_23.drop(columns=['TeamID_Team1', 'TeamID_Team2'])\n",
    "\n",
    "# Merge sample_24 with teams_24 for Team1 & Team2 details\n",
    "merged_sample_24 = sample_24.merge(teams_24, left_on='Team1', right_on='TeamID', suffixes=('', '_Team1'))\n",
    "merged_sample_24 = merged_sample_24.merge(teams_24, left_on='Team2', right_on='TeamID', suffixes=('_Team1', '_Team2'))\n",
    "merged_sample_24 = merged_sample_24.drop(columns=['TeamID_Team1', 'TeamID_Team2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all merged samples into a single DataFrame\n",
    "merged_all_samples = pd.concat([merged_sample_21, merged_sample_22, merged_sample_23, merged_sample_24], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166880</th>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>1101</td>\n",
       "      <td>70</td>\n",
       "      <td>1190</td>\n",
       "      <td>47</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166881</th>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>1104</td>\n",
       "      <td>81</td>\n",
       "      <td>1240</td>\n",
       "      <td>57</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166882</th>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>1111</td>\n",
       "      <td>81</td>\n",
       "      <td>1354</td>\n",
       "      <td>61</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166883</th>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>1113</td>\n",
       "      <td>94</td>\n",
       "      <td>1348</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166884</th>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>1114</td>\n",
       "      <td>71</td>\n",
       "      <td>1341</td>\n",
       "      <td>66</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170730</th>\n",
       "      <td>2021</td>\n",
       "      <td>132</td>\n",
       "      <td>1104</td>\n",
       "      <td>80</td>\n",
       "      <td>1261</td>\n",
       "      <td>79</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170731</th>\n",
       "      <td>2021</td>\n",
       "      <td>132</td>\n",
       "      <td>1159</td>\n",
       "      <td>85</td>\n",
       "      <td>1259</td>\n",
       "      <td>72</td>\n",
       "      <td>H</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170732</th>\n",
       "      <td>2021</td>\n",
       "      <td>132</td>\n",
       "      <td>1222</td>\n",
       "      <td>91</td>\n",
       "      <td>1153</td>\n",
       "      <td>54</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170733</th>\n",
       "      <td>2021</td>\n",
       "      <td>132</td>\n",
       "      <td>1228</td>\n",
       "      <td>91</td>\n",
       "      <td>1326</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170734</th>\n",
       "      <td>2021</td>\n",
       "      <td>132</td>\n",
       "      <td>1382</td>\n",
       "      <td>74</td>\n",
       "      <td>1433</td>\n",
       "      <td>65</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3855 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT\n",
       "166880    2021      23     1101      70     1190      47    N      0\n",
       "166881    2021      23     1104      81     1240      57    H      0\n",
       "166882    2021      23     1111      81     1354      61    A      0\n",
       "166883    2021      23     1113      94     1348      88    N      0\n",
       "166884    2021      23     1114      71     1341      66    N      0\n",
       "...        ...     ...      ...     ...      ...     ...  ...    ...\n",
       "170730    2021     132     1104      80     1261      79    N      0\n",
       "170731    2021     132     1159      85     1259      72    H      0\n",
       "170732    2021     132     1222      91     1153      54    N      0\n",
       "170733    2021     132     1228      91     1326      88    N      1\n",
       "170734    2021     132     1382      74     1433      65    N      0\n",
       "\n",
       "[3855 rows x 8 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_21 = pd.concat([\n",
    "    merged_sample_21.merge(results_21, how='inner', left_on=['Team1', 'Team2'], right_on=['WTeamID', 'LTeamID']),\n",
    "    merged_sample_21.merge(results_21, how='inner', left_on=['Team1', 'Team2'], right_on=['LTeamID', 'WTeamID'])\n",
    "], ignore_index=True)\n",
    "\n",
    "data_22 = pd.concat([\n",
    "    merged_sample_22.merge(results_22, how='inner', left_on=['Team1', 'Team2'], right_on=['WTeamID', 'LTeamID']),\n",
    "    merged_sample_22.merge(results_22, how='inner', left_on=['Team1', 'Team2'], right_on=['LTeamID', 'WTeamID'])\n",
    "], ignore_index=True)\n",
    "\n",
    "data_23 = pd.concat([\n",
    "    merged_sample_23.merge(results_23, how='inner', left_on=['Team1', 'Team2'], right_on=['WTeamID', 'LTeamID']),\n",
    "    merged_sample_23.merge(results_23, how='inner', left_on=['Team1', 'Team2'], right_on=['LTeamID', 'WTeamID'])\n",
    "], ignore_index=True)\n",
    "\n",
    "data_24 = pd.concat([\n",
    "    merged_sample_24.merge(results_24, how='inner', left_on=['Team1', 'Team2'], right_on=['WTeamID', 'LTeamID']),\n",
    "    merged_sample_24.merge(results_24, how='inner', left_on=['Team1', 'Team2'], right_on=['LTeamID', 'WTeamID'])\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Season_x</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>TeamName_Team1</th>\n",
       "      <th>FirstD1Season_Team1</th>\n",
       "      <th>LastD1Season_Team1</th>\n",
       "      <th>Wins_Team1</th>\n",
       "      <th>AvgScoreDifference_Team1</th>\n",
       "      <th>POM_avg_Team1</th>\n",
       "      <th>FG_PCT_Team1</th>\n",
       "      <th>FG3_PCT_Team1</th>\n",
       "      <th>FT_PCT_Team1</th>\n",
       "      <th>REB_Team1</th>\n",
       "      <th>AST_Team1</th>\n",
       "      <th>TO_Team1</th>\n",
       "      <th>STL_Team1</th>\n",
       "      <th>BLK_Team1</th>\n",
       "      <th>PF_Team1</th>\n",
       "      <th>TeamName_Team2</th>\n",
       "      <th>FirstD1Season_Team2</th>\n",
       "      <th>LastD1Season_Team2</th>\n",
       "      <th>Wins_Team2</th>\n",
       "      <th>AvgScoreDifference_Team2</th>\n",
       "      <th>POM_avg_Team2</th>\n",
       "      <th>FG_PCT_Team2</th>\n",
       "      <th>FG3_PCT_Team2</th>\n",
       "      <th>FT_PCT_Team2</th>\n",
       "      <th>REB_Team2</th>\n",
       "      <th>AST_Team2</th>\n",
       "      <th>TO_Team2</th>\n",
       "      <th>STL_Team2</th>\n",
       "      <th>BLK_Team2</th>\n",
       "      <th>PF_Team2</th>\n",
       "      <th>Season_y</th>\n",
       "      <th>DayNum</th>\n",
       "      <th>WTeamID</th>\n",
       "      <th>WScore</th>\n",
       "      <th>LTeamID</th>\n",
       "      <th>LScore</th>\n",
       "      <th>WLoc</th>\n",
       "      <th>NumOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>2021_1460_1464</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1460</td>\n",
       "      <td>1464</td>\n",
       "      <td>Wright St</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.541667</td>\n",
       "      <td>14.541667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Youngstown St</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1.608696</td>\n",
       "      <td>-1.608696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>67</td>\n",
       "      <td>1464</td>\n",
       "      <td>74</td>\n",
       "      <td>1460</td>\n",
       "      <td>72</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>2021_1465_1469</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1465</td>\n",
       "      <td>1469</td>\n",
       "      <td>Cal Baptist</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.210526</td>\n",
       "      <td>-0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Utah Tech</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-10.578947</td>\n",
       "      <td>-10.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>89</td>\n",
       "      <td>1469</td>\n",
       "      <td>79</td>\n",
       "      <td>1465</td>\n",
       "      <td>75</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3852</th>\n",
       "      <td>2021_1466_1468</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1466</td>\n",
       "      <td>1468</td>\n",
       "      <td>North Alabama</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-3.750000</td>\n",
       "      <td>-3.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bellarmine</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>102</td>\n",
       "      <td>1468</td>\n",
       "      <td>66</td>\n",
       "      <td>1466</td>\n",
       "      <td>64</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3853</th>\n",
       "      <td>2021_1466_1468</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1466</td>\n",
       "      <td>1468</td>\n",
       "      <td>North Alabama</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-3.750000</td>\n",
       "      <td>-3.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bellarmine</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>4.277778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>103</td>\n",
       "      <td>1468</td>\n",
       "      <td>87</td>\n",
       "      <td>1466</td>\n",
       "      <td>63</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>2021_1469_1470</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021</td>\n",
       "      <td>1469</td>\n",
       "      <td>1470</td>\n",
       "      <td>Utah Tech</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-10.578947</td>\n",
       "      <td>-10.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tarleton St</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.266667</td>\n",
       "      <td>-4.266667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>109</td>\n",
       "      <td>1470</td>\n",
       "      <td>77</td>\n",
       "      <td>1469</td>\n",
       "      <td>59</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID  Pred  Season_x  Team1  ...  LTeamID LScore  WLoc  NumOT\n",
       "3850  2021_1460_1464   0.5      2021   1460  ...     1460     72     A      0\n",
       "3851  2021_1465_1469   0.5      2021   1465  ...     1465     75     A      0\n",
       "3852  2021_1466_1468   0.5      2021   1466  ...     1466     64     A      0\n",
       "3853  2021_1466_1468   0.5      2021   1466  ...     1466     63     A      0\n",
       "3854  2021_1469_1470   0.5      2021   1469  ...     1469     59     A      0\n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_21.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract matchups with regular season results to train with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(sample_submission):\n",
    "    train_data = sample_submission[sample_submission['DayNum'].notnull()]\n",
    "\n",
    "    def classify(row):\n",
    "        return 1 if row['Team1'] == row['WTeamID'] else 0\n",
    "\n",
    "    train_data['Outcome'] = train_data.apply(classify, axis=1)\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_21 = prepare_training_data(data_21)\n",
    "train_22 = prepare_training_data(data_22)\n",
    "train_23 = prepare_training_data(data_23)\n",
    "train_24 = prepare_training_data(data_24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    1943\n",
       "1    1912\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_21['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define features and target\n",
    "features = ['Wins_Team1', 'AvgScoreDifference_Team1', 'POM_avg_Team1', 'FG_PCT_Team1', 'FG3_PCT_Team1', 'FT_PCT_Team1', \n",
    "            'REB_Team1', 'AST_Team1', 'TO_Team1', 'STL_Team1', 'BLK_Team1', 'PF_Team1', \n",
    "            'Wins_Team2', 'AvgScoreDifference_Team2', 'POM_avg_Team2', 'FG_PCT_Team2', 'FG3_PCT_Team2', 'FT_PCT_Team2', \n",
    "            'REB_Team2', 'AST_Team2', 'TO_Team2', 'STL_Team2', 'BLK_Team2', 'PF_Team2']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data_21, test_data_21 = train_test_split(train_21, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_21 = train_data_21[features]\n",
    "y_train_21 = train_data_21['Outcome']\n",
    "\n",
    "train_data_22, test_data_22 = train_test_split(train_22, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_22 = train_data_22[features]\n",
    "y_train_22 = train_data_22['Outcome']\n",
    "\n",
    "# Split the 2023 training data into training and testing sets\n",
    "train_data_23, test_data_23 = train_test_split(train_23, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_23 = train_data_23[features]\n",
    "y_train_23 = train_data_23['Outcome']\n",
    "\n",
    "# Split the 2024 training data into training and testing sets\n",
    "train_data_24, test_data_24 = train_test_split(train_24, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_24 = train_data_24[features]\n",
    "y_train_24 = train_data_24['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n",
      "Random Forest Model accuracy on train_data: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_21, y_train_21)\n",
    "\n",
    "print(\"Model trained successfully.\")\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred_21 = rf_model.predict(X_train_21)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train_21, y_train_pred_21)\n",
    "print(f\"Random Forest Model accuracy on train_data: {train_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "Train set accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "#RF model 22 Training\n",
    "# set warm_start and increase num of estimators\n",
    "rf_model.set_params(warm_start=True, n_estimators=rf_model.n_estimators + 50)  # Add 50 more trees\n",
    "rf_model.fit(X_train_22, y_train_22) # fit additional 10 trees\n",
    "print(len(rf_model.estimators_)) # Print the number of trees\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_22 = rf_model.predict(X_train_22)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_22 = accuracy_score(y_train_22, y_train_pred_22)\n",
    "print(f\"Train set accuracy: {train_accuracy_22:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Train set accuracy for 2023: 0.81\n"
     ]
    }
   ],
   "source": [
    "# RF model 23 Training\n",
    "# Set warm_start and increase the number of estimators\n",
    "rf_model.set_params(warm_start=True, n_estimators=rf_model.n_estimators + 50)  # Add 50 more trees\n",
    "rf_model.fit(X_train_23, y_train_23)  # Fit additional trees\n",
    "print(len(rf_model.estimators_))  # Print the number of trees\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_23 = rf_model.predict(X_train_23)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_23 = accuracy_score(y_train_23, y_train_pred_23)\n",
    "print(f\"Train set accuracy for 2023: {train_accuracy_23:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "Train set accuracy for 2024: 0.79\n"
     ]
    }
   ],
   "source": [
    "# RF model 24 Training\n",
    "# Set warm_start and increase the number of estimators\n",
    "rf_model.set_params(warm_start=True, n_estimators=rf_model.n_estimators + 50)  # Add 50 more trees\n",
    "rf_model.fit(X_train_24, y_train_24)  # Fit additional trees\n",
    "print(len(rf_model.estimators_))  # Print the number of trees\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_24 = rf_model.predict(X_train_24)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_24 = accuracy_score(y_train_24, y_train_pred_24)\n",
    "print(f\"Train set accuracy for 2024: {train_accuracy_24:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model brier score loss on 2021 test_data: 0.29\n",
      "F1 Score for RF model: 0.72\n",
      "RF model brier score loss on 2022 test_data: 0.26\n",
      "F1 Score for RF model: 0.72\n",
      "RF model brier score loss on 2023 test_data: 0.29\n",
      "F1 Score for RF model: 0.71\n",
      "RF model brier score loss on 2024 test_data: 0.30\n",
      "F1 Score for RF model: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2021 test data\n",
    "y_test_pred_rf_21 = rf_model.predict(test_data_21[features])\n",
    "\n",
    "# Calculate accuracy on 2021 test data\n",
    "test_accuracy = brier_score_loss(test_data_21['Outcome'], y_test_pred_rf_21) #Assess RF\n",
    "f1_score_rf = f1_score(test_data_21['Outcome'], y_test_pred_rf_21)\n",
    "print(f\"RF model brier score loss on 2021 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for RF model: {f1_score_rf:.2f}\")\n",
    "\n",
    "# Predict on 2022 test data\n",
    "y_test_pred_rf_22 = rf_model.predict(test_data_22[features])\n",
    "\n",
    "# Calculate accuracy on 2022 test data\n",
    "test_accuracy_22 = brier_score_loss(test_data_22['Outcome'], y_test_pred_rf_22) #Assess RF\n",
    "f1_score_rf_22 = f1_score(test_data_22['Outcome'], y_test_pred_rf_22)\n",
    "print(f\"RF model brier score loss on 2022 test_data: {test_accuracy_22:.2f}\")\n",
    "print(f\"F1 Score for RF model: {f1_score_rf_22:.2f}\")\n",
    "\n",
    "# Predict on 2023 test data\n",
    "y_test_pred_rf_23 = rf_model.predict(test_data_23[features])\n",
    "\n",
    "# Calculate accuracy on 2023 test data\n",
    "test_accuracy_23 = brier_score_loss(test_data_23['Outcome'], y_test_pred_rf_23) #Assess RF\n",
    "f1_score_rf_23 = f1_score(test_data_23['Outcome'], y_test_pred_rf_23)\n",
    "print(f\"RF model brier score loss on 2023 test_data: {test_accuracy_23:.2f}\")\n",
    "print(f\"F1 Score for RF model: {f1_score_rf_23:.2f}\")\n",
    "\n",
    "# Predict on 2024 test data\n",
    "y_test_pred_rf_24 = rf_model.predict(test_data_24[features])\n",
    "\n",
    "# Calculate accuracy on 2024 test data\n",
    "test_accuracy_24 = brier_score_loss(test_data_24['Outcome'], y_test_pred_rf_24) #Assess RF\n",
    "f1_score_rf_24 = f1_score(test_data_24['Outcome'], y_test_pred_rf_24)\n",
    "print(f\"RF model brier score loss on 2024 test_data: {test_accuracy_24:.2f}\")\n",
    "print(f\"F1 Score for RF model: {f1_score_rf_24:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>TeamName_Team1</th>\n",
       "      <th>FirstD1Season_Team1</th>\n",
       "      <th>LastD1Season_Team1</th>\n",
       "      <th>Wins_Team1</th>\n",
       "      <th>AvgScoreDifference_Team1</th>\n",
       "      <th>POM_avg_Team1</th>\n",
       "      <th>FG_PCT_Team1</th>\n",
       "      <th>FG3_PCT_Team1</th>\n",
       "      <th>FT_PCT_Team1</th>\n",
       "      <th>REB_Team1</th>\n",
       "      <th>AST_Team1</th>\n",
       "      <th>TO_Team1</th>\n",
       "      <th>STL_Team1</th>\n",
       "      <th>BLK_Team1</th>\n",
       "      <th>PF_Team1</th>\n",
       "      <th>TeamName_Team2</th>\n",
       "      <th>FirstD1Season_Team2</th>\n",
       "      <th>LastD1Season_Team2</th>\n",
       "      <th>Wins_Team2</th>\n",
       "      <th>AvgScoreDifference_Team2</th>\n",
       "      <th>POM_avg_Team2</th>\n",
       "      <th>FG_PCT_Team2</th>\n",
       "      <th>FG3_PCT_Team2</th>\n",
       "      <th>FT_PCT_Team2</th>\n",
       "      <th>REB_Team2</th>\n",
       "      <th>AST_Team2</th>\n",
       "      <th>TO_Team2</th>\n",
       "      <th>STL_Team2</th>\n",
       "      <th>BLK_Team2</th>\n",
       "      <th>PF_Team2</th>\n",
       "      <th>Predicted_Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_1101_1102</td>\n",
       "      <td>0.853600</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1102</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>0.05646</td>\n",
       "      <td>0.092365</td>\n",
       "      <td>-0.005793</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.130435</td>\n",
       "      <td>-4.869565</td>\n",
       "      <td>2.26087</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-13.200000</td>\n",
       "      <td>-13.200000</td>\n",
       "      <td>-0.054251</td>\n",
       "      <td>-0.032093</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>-11.360000</td>\n",
       "      <td>-2.400000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021_1101_1103</td>\n",
       "      <td>0.678629</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1103</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>0.05646</td>\n",
       "      <td>0.092365</td>\n",
       "      <td>-0.005793</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.130435</td>\n",
       "      <td>-4.869565</td>\n",
       "      <td>2.26087</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>Akron</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.037146</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021_1101_1104</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1104</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>0.05646</td>\n",
       "      <td>0.092365</td>\n",
       "      <td>-0.005793</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.130435</td>\n",
       "      <td>-4.869565</td>\n",
       "      <td>2.26087</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.024123</td>\n",
       "      <td>0.068166</td>\n",
       "      <td>0.025954</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021_1101_1105</td>\n",
       "      <td>0.799133</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1105</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>0.05646</td>\n",
       "      <td>0.092365</td>\n",
       "      <td>-0.005793</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.130435</td>\n",
       "      <td>-4.869565</td>\n",
       "      <td>2.26087</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-3.866667</td>\n",
       "      <td>-3.866667</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>-0.012357</td>\n",
       "      <td>-0.047485</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.533333</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021_1101_1106</td>\n",
       "      <td>0.839600</td>\n",
       "      <td>2021</td>\n",
       "      <td>1101</td>\n",
       "      <td>1106</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>14.565217</td>\n",
       "      <td>0.05646</td>\n",
       "      <td>0.092365</td>\n",
       "      <td>-0.005793</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.130435</td>\n",
       "      <td>-4.869565</td>\n",
       "      <td>2.26087</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.333333</td>\n",
       "      <td>-7.333333</td>\n",
       "      <td>-0.055723</td>\n",
       "      <td>-0.009602</td>\n",
       "      <td>-0.043857</td>\n",
       "      <td>-1.777778</td>\n",
       "      <td>-2.888889</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>-1.611111</td>\n",
       "      <td>-1.777778</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      Pred  Season  ...  BLK_Team2  PF_Team2 Predicted_Outcome\n",
       "0  2021_1101_1102  0.853600    2021  ...   0.360000 -0.120000                 1\n",
       "1  2021_1101_1103  0.678629    2021  ...   1.333333  0.095238                 1\n",
       "2  2021_1101_1104  0.468400    2021  ...  -0.500000  0.166667                 0\n",
       "3  2021_1101_1105  0.799133    2021  ...   0.933333  1.466667                 1\n",
       "4  2021_1101_1106  0.839600    2021  ...  -1.777778 -2.500000                 1\n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on merged_all_samples\n",
    "merged_all_samples['Predicted_Outcome'] = rf_model.predict(merged_all_samples_features)\n",
    "\n",
    "# Display the first few rows of the predictions\n",
    "merged_all_samples.fillna(0, inplace=True)\n",
    "\n",
    "# Update 'Pred' feature with probabilities\n",
    "merged_all_samples['Pred'] = rf_model.predict_proba(merged_all_samples[features])[:, 1]\n",
    "\n",
    "# Display the first few rows with updated probabilities\n",
    "merged_all_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_all_samples[['ID', 'Pred']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSubmissionStage2['Season'] = SampleSubmissionStage2['ID'].apply(lambda x: int(x.split('_')[0]))\n",
    "SampleSubmissionStage2['Team1'] = SampleSubmissionStage2['ID'].apply(lambda x: int(x.split('_')[1]))\n",
    "SampleSubmissionStage2['Team2'] = SampleSubmissionStage2['ID'].apply(lambda x: int(x.split('_')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\4031966792.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_25['Wins'] = teams_25['TeamID'].apply(lambda x: record_wins(x, results_25))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\4031966792.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_25['AvgScoreDifference'] = teams_25['TeamID'].apply(lambda x: avg_score_difference(x, results_25))\n",
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_10100\\4031966792.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teams_25['POM_avg'] = teams_25['TeamID'].apply(lambda x: avg_score_difference(x, results_25))\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for the 2025 season\n",
    "teams_25, results_25, rankings_25, sample_25, detailed_25 = regular_season_data(\n",
    "    2025, MTeams, MRegularSeasonCompactResults, MMasseyOrdinals, SampleSubmissionStage2, MRegularSeasonDetailedResults\n",
    ")\n",
    "\n",
    "# Add calculated features for the 2025 season\n",
    "teams_25['Wins'] = teams_25['TeamID'].apply(lambda x: record_wins(x, results_25))\n",
    "teams_25['AvgScoreDifference'] = teams_25['TeamID'].apply(lambda x: avg_score_difference(x, results_25))\n",
    "teams_25['POM_avg'] = teams_25['TeamID'].apply(lambda x: avg_score_difference(x, results_25))\n",
    "\n",
    "team_stats = teams_25['TeamID'].apply(lambda x: team_stats_differences(x, detailed_25))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "teams_25 = pd.concat([teams_25, team_stats_df], axis=1)\n",
    "\n",
    "# Merge sample_25 with teams_25 for Team1 & Team2 details\n",
    "merged_sample_25 = sample_25.merge(teams_25, left_on='Team1', right_on='TeamID', suffixes=('', '_Team1'))\n",
    "merged_sample_25 = merged_sample_25.merge(teams_25, left_on='Team2', right_on='TeamID', suffixes=('_Team1', '_Team2'))\n",
    "merged_sample_25 = merged_sample_25.drop(columns=['TeamID_Team1', 'TeamID_Team2'])\n",
    "\n",
    "# Extract matchups with regular season results for training\n",
    "data_25 = pd.concat([\n",
    "    merged_sample_25.merge(results_25, how='inner', left_on=['Team1', 'Team2'], right_on=['WTeamID', 'LTeamID']),\n",
    "    merged_sample_25.merge(results_25, how='inner', left_on=['Team1', 'Team2'], right_on=['LTeamID', 'WTeamID'])\n",
    "], ignore_index=True)\n",
    "\n",
    "# Prepare training data for the 2025 season\n",
    "train_25 = prepare_training_data(data_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Train set accuracy for 2025: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Define features and target for train_25\n",
    "X_train_25 = train_25[features]\n",
    "y_train_25 = train_25['Outcome']\n",
    "\n",
    "# Set warm_start and increase the number of estimators\n",
    "rf_model.set_params(warm_start=True, n_estimators=rf_model.n_estimators + 50)  # Add 50 more trees\n",
    "rf_model.fit(X_train_25, y_train_25)  # Fit additional trees\n",
    "print(len(rf_model.estimators_))  # Print the number of trees\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_25 = rf_model.predict(X_train_25)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_25 = accuracy_score(y_train_25, y_train_pred_25)\n",
    "print(f\"Train set accuracy for 2025: {train_accuracy_25:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>TeamName_Team1</th>\n",
       "      <th>FirstD1Season_Team1</th>\n",
       "      <th>LastD1Season_Team1</th>\n",
       "      <th>Wins_Team1</th>\n",
       "      <th>AvgScoreDifference_Team1</th>\n",
       "      <th>POM_avg_Team1</th>\n",
       "      <th>FG_PCT_Team1</th>\n",
       "      <th>FG3_PCT_Team1</th>\n",
       "      <th>FT_PCT_Team1</th>\n",
       "      <th>REB_Team1</th>\n",
       "      <th>AST_Team1</th>\n",
       "      <th>TO_Team1</th>\n",
       "      <th>STL_Team1</th>\n",
       "      <th>BLK_Team1</th>\n",
       "      <th>PF_Team1</th>\n",
       "      <th>TeamName_Team2</th>\n",
       "      <th>FirstD1Season_Team2</th>\n",
       "      <th>LastD1Season_Team2</th>\n",
       "      <th>Wins_Team2</th>\n",
       "      <th>AvgScoreDifference_Team2</th>\n",
       "      <th>POM_avg_Team2</th>\n",
       "      <th>FG_PCT_Team2</th>\n",
       "      <th>FG3_PCT_Team2</th>\n",
       "      <th>FT_PCT_Team2</th>\n",
       "      <th>REB_Team2</th>\n",
       "      <th>AST_Team2</th>\n",
       "      <th>TO_Team2</th>\n",
       "      <th>STL_Team2</th>\n",
       "      <th>BLK_Team2</th>\n",
       "      <th>PF_Team2</th>\n",
       "      <th>Predicted_Outcome</th>\n",
       "      <th>Predicted_Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025_1101_1102</td>\n",
       "      <td>0.692151</td>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1102</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-0.027903</td>\n",
       "      <td>-0.037382</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>-3.363636</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>-1.727273</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.866667</td>\n",
       "      <td>-10.866667</td>\n",
       "      <td>-0.053142</td>\n",
       "      <td>-0.031143</td>\n",
       "      <td>-0.066576</td>\n",
       "      <td>-4.423077</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>2.076923</td>\n",
       "      <td>-0.923077</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025_1101_1103</td>\n",
       "      <td>0.127448</td>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1103</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-0.027903</td>\n",
       "      <td>-0.037382</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>-3.363636</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>-1.727273</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>Akron</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.107143</td>\n",
       "      <td>7.107143</td>\n",
       "      <td>0.039659</td>\n",
       "      <td>0.050411</td>\n",
       "      <td>0.020265</td>\n",
       "      <td>3.958333</td>\n",
       "      <td>6.166667</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025_1101_1104</td>\n",
       "      <td>0.144611</td>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1104</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-0.027903</td>\n",
       "      <td>-0.037382</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>-3.363636</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>-1.727273</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.896552</td>\n",
       "      <td>10.896552</td>\n",
       "      <td>0.065714</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>7.840000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>-1.760000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-2.760000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025_1101_1105</td>\n",
       "      <td>0.586688</td>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1105</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-0.027903</td>\n",
       "      <td>-0.037382</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>-3.363636</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>-1.727273</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-0.075168</td>\n",
       "      <td>-0.064070</td>\n",
       "      <td>-0.044200</td>\n",
       "      <td>-2.304348</td>\n",
       "      <td>-3.347826</td>\n",
       "      <td>1.043478</td>\n",
       "      <td>-0.913043</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>3.086957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025_1101_1106</td>\n",
       "      <td>0.398028</td>\n",
       "      <td>2025</td>\n",
       "      <td>1101</td>\n",
       "      <td>1106</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-3.153846</td>\n",
       "      <td>-0.027903</td>\n",
       "      <td>-0.037382</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>-3.363636</td>\n",
       "      <td>-0.409091</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>-1.727273</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>-1.214286</td>\n",
       "      <td>-0.040304</td>\n",
       "      <td>-0.016624</td>\n",
       "      <td>-0.011400</td>\n",
       "      <td>-5.560000</td>\n",
       "      <td>-1.720000</td>\n",
       "      <td>-2.680000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>-0.280000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      Pred  ...  Predicted_Outcome  Predicted_Probability\n",
       "0  2025_1101_1102  0.692151  ...                  1               0.692151\n",
       "1  2025_1101_1103  0.127448  ...                  0               0.127448\n",
       "2  2025_1101_1104  0.144611  ...                  0               0.144611\n",
       "3  2025_1101_1105  0.586688  ...                  1               0.586688\n",
       "4  2025_1101_1106  0.398028  ...                  0               0.398028\n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features for prediction\n",
    "merged_sample_25_features = merged_sample_25[features]\n",
    "\n",
    "# Make predictions\n",
    "merged_sample_25['Predicted_Outcome'] = rf_model.predict(merged_sample_25_features)\n",
    "\n",
    "# Add probabilities for the predictions\n",
    "merged_sample_25['Pred'] = rf_model.predict_proba(merged_sample_25_features)[:, 1]\n",
    "\n",
    "# Display the first few rows of the predictions\n",
    "merged_sample_25.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sample_25[['ID', 'Pred']].to_csv('submission_2025.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
