{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WTeams = pd.read_csv('WTeams.csv')\n",
    "WSeasons = pd.read_csv('WSeasons.csv')\n",
    "WRegularSeasonCompactResults = pd.read_csv('WRegularSeasonCompactResults.csv')\n",
    "WRegularSeasonDetailedResults = pd.read_csv('WRegularSeasonDetailedResults.csv')\n",
    "SampleSubmissionStage1 = pd.read_csv('SampleSubmissionStage1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSubmissionStage1['Season'] = SampleSubmissionStage1['ID'].apply(lambda x: int(x.split('_')[0]))\n",
    "SampleSubmissionStage1['Team1'] = SampleSubmissionStage1['ID'].apply(lambda x: int(x.split('_')[1]))\n",
    "SampleSubmissionStage1['Team2'] = SampleSubmissionStage1['ID'].apply(lambda x: int(x.split('_')[2]))\n",
    "SampleSubmissionStage1 = SampleSubmissionStage1[SampleSubmissionStage1['Team1'].astype(str).str.startswith('3') & SampleSubmissionStage1['Team2'].astype(str).str.startswith('3')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def record_record(Team1, data):\n",
    "    Team1_wins = 0\n",
    "    for index, row in data.iterrows():\n",
    "        if row['WTeamID'] == Team1:\n",
    "            Team1_wins += 1\n",
    "    return Team1_wins\n",
    "\n",
    "def avg_score_difference(Team1, data):\n",
    "    Team1_score_difference = 0\n",
    "    games = 0\n",
    "    for index, row in data.iterrows():\n",
    "        if row['WTeamID'] == Team1:\n",
    "            Team1_score_difference += row['WScore'] - row['LScore']\n",
    "            games += 1\n",
    "        if row['LTeamID'] == Team1:\n",
    "            Team1_score_difference += row['LScore'] - row['WScore']\n",
    "            games += 1\n",
    "    return Team1_score_difference/games if games != 0 else 0\n",
    "\n",
    "def team_stats_differences(Team1, data):\n",
    "    Team1_FG_PCT = 0\n",
    "    Team1_FG3_PCT = 0\n",
    "    Team1_FT_PCT = 0\n",
    "    Team1_REB = 0\n",
    "    Team1_AST = 0\n",
    "    Team1_TO = 0\n",
    "    Team1_STL = 0\n",
    "    Team1_BLK = 0\n",
    "    Team1_PF = 0\n",
    "    games = 0\n",
    "    for index, row in data.iterrows():\n",
    "        if row['WTeamID'] == Team1:\n",
    "            Team1_FG_PCT += (row['WFGM'] / row['WFGA'] if row['WFGA'] != 0 else 0) - (row['LFGM'] / row['LFGA'] if row['LFGA'] != 0 else 0)\n",
    "            Team1_FG3_PCT += (row['WFGM3'] / row['WFGA3'] if row['WFGA3'] != 0 else 0) - (row['LFGM3'] / row['LFGA3'] if row['LFGA3'] != 0 else 0)\n",
    "            Team1_FT_PCT += (row['WFTM'] / row['WFTA'] if row['WFTA'] != 0 else 0) - (row['LFTM'] / row['LFTA'] if row['LFTA'] != 0 else 0)\n",
    "            Team1_REB += (row['WOR'] + row['WDR']) - (row['LOR'] + row['LDR'])\n",
    "            Team1_AST += row['WAst'] - row['LAst']\n",
    "            Team1_TO += row['WTO'] - row['LTO']\n",
    "            Team1_STL += row['WStl'] - row['LStl']\n",
    "            Team1_BLK += row['WBlk'] - row['LBlk']\n",
    "            Team1_PF += row['WPF'] - row['LPF']\n",
    "            games += 1\n",
    "        if row['LTeamID'] == Team1:\n",
    "            Team1_FG_PCT += (row['LFGM'] / row['LFGA'] if row['LFGA'] != 0 else 0) - (row['WFGM'] / row['WFGA'] if row['WFGA'] != 0 else 0)\n",
    "            Team1_FG3_PCT += (row['LFGM3'] / row['LFGA3'] if row['LFGA3'] != 0 else 0) - (row['WFGM3'] / row['WFGA3'] if row['WFGA3'] != 0 else 0)\n",
    "            Team1_FT_PCT += (row['LFTM'] / row['LFTA'] if row['LFTA'] != 0 else 0) - (row['WFTM'] / row['WFTA'] if row['WFTA'] != 0 else 0)\n",
    "            Team1_REB += (row['LOR'] + row['LDR']) - (row['WOR'] + row['WDR'])\n",
    "            Team1_AST += row['LAst'] - row['WAst']\n",
    "            Team1_TO += row['LTO'] - row['WTO']\n",
    "            Team1_STL += row['LStl'] - row['WStl']\n",
    "            Team1_BLK += row['LBlk'] - row['WBlk']\n",
    "            Team1_PF += row['LPF'] - row['WPF']\n",
    "            games += 1\n",
    "    return (Team1_FG_PCT/games if games != 0 else 0, \n",
    "            Team1_FG3_PCT/games if games != 0 else 0, \n",
    "            Team1_FT_PCT/games if games != 0 else 0, \n",
    "            Team1_REB/games if games != 0 else 0, \n",
    "            Team1_AST/games if games != 0 else 0, \n",
    "            Team1_TO/games if games != 0 else 0, \n",
    "            Team1_STL/games if games != 0 else 0, \n",
    "            Team1_BLK/games if games != 0 else 0, \n",
    "            Team1_PF/games if games != 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelInput21 = pd.DataFrame(WTeams['TeamID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelInput21['Wins'] = ModelInput21['TeamID'].apply(lambda x: record_record(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2021]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelInput21['avg_score_diff'] = ModelInput21['TeamID'].apply(lambda x: avg_score_difference(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2021]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = ModelInput21['TeamID'].apply(lambda x: team_stats_differences(x, WRegularSeasonDetailedResults[WRegularSeasonDetailedResults['Season'] == 2021]))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "ModelInput21 = pd.concat([ModelInput21, team_stats_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRegularSeasonCompactResults['Outcome'] = np.where(\n",
    "    WRegularSeasonCompactResults['WTeamID'] > WRegularSeasonCompactResults['LTeamID'], \n",
    "    1, \n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelInput22 = pd.DataFrame(WTeams['TeamID'])\n",
    "ModelInput23 = pd.DataFrame(WTeams['TeamID'])\n",
    "ModelInput24 = pd.DataFrame(WTeams['TeamID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelInput22['Wins'] = ModelInput22['TeamID'].apply(lambda x: record_record(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2022]))\n",
    "ModelInput23['Wins'] = ModelInput23['TeamID'].apply(lambda x: record_record(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2023]))\n",
    "ModelInput24['Wins'] = ModelInput24['TeamID'].apply(lambda x: record_record(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2024]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelInput22['avg_score_diff'] = ModelInput22['TeamID'].apply(lambda x: avg_score_difference(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2022]))\n",
    "ModelInput23['avg_score_diff'] = ModelInput23['TeamID'].apply(lambda x: avg_score_difference(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2023]))\n",
    "ModelInput24['avg_score_diff'] = ModelInput24['TeamID'].apply(lambda x: avg_score_difference(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2024]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = ModelInput22['TeamID'].apply(lambda x: team_stats_differences(x, WRegularSeasonDetailedResults[WRegularSeasonDetailedResults['Season'] == 2022]))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "ModelInput22 = pd.concat([ModelInput22, team_stats_df], axis=1)\n",
    "team_stats = ModelInput23['TeamID'].apply(lambda x: team_stats_differences(x, WRegularSeasonDetailedResults[WRegularSeasonDetailedResults['Season'] == 2023]))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "ModelInput23 = pd.concat([ModelInput23, team_stats_df], axis=1)\n",
    "team_stats = ModelInput22['TeamID'].apply(lambda x: team_stats_differences(x, WRegularSeasonDetailedResults[WRegularSeasonDetailedResults['Season'] == 2024]))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "ModelInput24 = pd.concat([ModelInput24, team_stats_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data for the year 2021\n",
    "train_data = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2021]\n",
    "train_data = train_data.merge(ModelInput21, left_on='Team1', right_on='TeamID')\n",
    "train_data = train_data.merge(ModelInput21, left_on='Team2', right_on='TeamID', suffixes=('_Team1', '_Team2'))\n",
    "train_data = train_data.merge(\n",
    "    WRegularSeasonCompactResults[['Season', 'WTeamID', 'LTeamID', 'Outcome']],\n",
    "    how='inner',\n",
    "    left_on=['Season', 'Team1', 'Team2'],\n",
    "    right_on=['Season', 'WTeamID', 'LTeamID']\n",
    ").merge(\n",
    "    WRegularSeasonCompactResults[['Season', 'WTeamID', 'LTeamID', 'Outcome']],\n",
    "    how='left',\n",
    "    left_on=['Season', 'Team2', 'Team1'],\n",
    "    right_on=['Season', 'WTeamID', 'LTeamID'],\n",
    "    suffixes=('_Team1_Win', '_Team2_Win')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Outcome_Team2_Win'].fillna(0, inplace=True)\n",
    "train_data.loc[train_data['Outcome_Team2_Win'] == 0, 'Outcome_Team1_Win'] = 1\n",
    "train_data['Outcome'] = np.where(\n",
    "    train_data['Outcome_Team1_Win'] == 1,\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "train_data.drop(columns=['WTeamID_Team2_Win', 'LTeamID_Team2_Win'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data for 2022\n",
    "train_data_2022 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2022]\n",
    "train_data_2022 = train_data_2022.merge(ModelInput22, left_on='Team1', right_on='TeamID')\n",
    "train_data_2022 = train_data_2022.merge(ModelInput22, left_on='Team2', right_on='TeamID', suffixes=('_Team1', '_Team2'))\n",
    "train_data_2022 = train_data_2022.merge(\n",
    "    WRegularSeasonCompactResults[['Season', 'WTeamID', 'LTeamID', 'Outcome']],\n",
    "    how='inner',\n",
    "    left_on=['Season', 'Team1', 'Team2'],\n",
    "    right_on=['Season', 'WTeamID', 'LTeamID']\n",
    ").merge(\n",
    "    WRegularSeasonCompactResults[['Season', 'WTeamID', 'LTeamID', 'Outcome']],\n",
    "    how='left',\n",
    "    left_on=['Season', 'Team2', 'Team1'],\n",
    "    right_on=['Season', 'WTeamID', 'LTeamID'],\n",
    "    suffixes=('_Team1_Win', '_Team2_Win')\n",
    ")\n",
    "\n",
    "train_data_2022['Outcome_Team2_Win'].fillna(0, inplace=True)\n",
    "train_data_2022.loc[train_data_2022['Outcome_Team2_Win'] == 0, 'Outcome_Team1_Win'] = 1\n",
    "train_data_2022['Outcome'] = np.where(\n",
    "    train_data_2022['Outcome_Team1_Win'] == 1,\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "train_data_2022.drop(columns=['WTeamID_Team2_Win', 'LTeamID_Team2_Win'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data formatting for 2023 model input completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_20044\\160510329.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data_2023['Outcome_Team2_Win'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data for 2023\n",
    "train_data_2023 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2023]\n",
    "train_data_2023 = train_data_2023.merge(ModelInput23, left_on='Team1', right_on='TeamID')\n",
    "train_data_2023 = train_data_2023.merge(ModelInput23, left_on='Team2', right_on='TeamID', suffixes=('_Team1', '_Team2'))\n",
    "train_data_2023 = train_data_2023.merge(\n",
    "    WRegularSeasonCompactResults[['Season', 'WTeamID', 'LTeamID', 'Outcome']],\n",
    "    how='inner',\n",
    "    left_on=['Season', 'Team1', 'Team2'],\n",
    "    right_on=['Season', 'WTeamID', 'LTeamID']\n",
    ").merge(\n",
    "    WRegularSeasonCompactResults[['Season', 'WTeamID', 'LTeamID', 'Outcome']],\n",
    "    how='left',\n",
    "    left_on=['Season', 'Team2', 'Team1'],\n",
    "    right_on=['Season', 'WTeamID', 'LTeamID'],\n",
    "    suffixes=('_Team1_Win', '_Team2_Win')\n",
    ")\n",
    "\n",
    "train_data_2023['Outcome_Team2_Win'].fillna(0, inplace=True)\n",
    "train_data_2023.loc[train_data_2023['Outcome_Team2_Win'] == 0, 'Outcome_Team1_Win'] = 1\n",
    "train_data_2023['Outcome'] = np.where(\n",
    "    train_data_2023['Outcome_Team1_Win'] == 1,\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "train_data_2023.drop(columns=['WTeamID_Team2_Win', 'LTeamID_Team2_Win'], inplace=True)\n",
    "\n",
    "print(\"Data formatting for 2023 model input completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data formatting for 2024 model input completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicko\\AppData\\Local\\Temp\\ipykernel_20044\\4016868138.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data_2024['Outcome_Team2_Win'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data for 2024\n",
    "train_data_2024 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2024]\n",
    "train_data_2024 = train_data_2024.merge(ModelInput24, left_on='Team1', right_on='TeamID')\n",
    "train_data_2024 = train_data_2024.merge(ModelInput24, left_on='Team2', right_on='TeamID', suffixes=('_Team1', '_Team2'))\n",
    "train_data_2024 = train_data_2024.merge(\n",
    "    WRegularSeasonCompactResults[['Season', 'WTeamID', 'LTeamID', 'Outcome']],\n",
    "    how='inner',\n",
    "    left_on=['Season', 'Team1', 'Team2'],\n",
    "    right_on=['Season', 'WTeamID', 'LTeamID']\n",
    ").merge(\n",
    "    WRegularSeasonCompactResults[['Season', 'WTeamID', 'LTeamID', 'Outcome']],\n",
    "    how='left',\n",
    "    left_on=['Season', 'Team2', 'Team1'],\n",
    "    right_on=['Season', 'WTeamID', 'LTeamID'],\n",
    "    suffixes=('_Team1_Win', '_Team2_Win')\n",
    ")\n",
    "\n",
    "train_data_2024['Outcome_Team2_Win'].fillna(0, inplace=True)\n",
    "train_data_2024.loc[train_data_2024['Outcome_Team2_Win'] == 0, 'Outcome_Team1_Win'] = 1\n",
    "train_data_2024['Outcome'] = np.where(\n",
    "    train_data_2024['Outcome_Team1_Win'] == 1,\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "train_data_2024.drop(columns=['WTeamID_Team2_Win', 'LTeamID_Team2_Win'], inplace=True)\n",
    "\n",
    "print(\"Data formatting for 2024 model input completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define features and target\n",
    "features = ['Wins_Team1', 'avg_score_diff_Team1', 'FG_PCT_Team1', 'FG3_PCT_Team1', 'FT_PCT_Team1', \n",
    "            'REB_Team1', 'AST_Team1', 'TO_Team1', 'STL_Team1', 'BLK_Team1', 'PF_Team1', \n",
    "            'Wins_Team2', 'avg_score_diff_Team2', 'FG_PCT_Team2', 'FG3_PCT_Team2', 'FT_PCT_Team2', \n",
    "            'REB_Team2', 'AST_Team2', 'TO_Team2', 'STL_Team2', 'BLK_Team2', 'PF_Team2']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data_21, test_data_21 = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_21 = train_data[features]\n",
    "y_train_21 = train_data['Outcome']\n",
    "\n",
    "train_data_22, test_data_22 = train_test_split(train_data_2022, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_22 = train_data_22[features]\n",
    "y_train_22 = train_data_22['Outcome']\n",
    "\n",
    "# Split the 2023 training data into training and testing sets\n",
    "train_data_23, test_data_23 = train_test_split(train_data_2023, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_23 = train_data_23[features]\n",
    "y_train_23 = train_data_23['Outcome']\n",
    "\n",
    "# Split the 2024 training data into training and testing sets\n",
    "train_data_24, test_data_24 = train_test_split(train_data_2024, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_24 = train_data_24[features]\n",
    "y_train_24 = train_data_24['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n",
      "Random Forest Model accuracy on train_data: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_21, y_train_21)\n",
    "\n",
    "print(\"Model trained successfully.\")\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred_21 = rf_model.predict(X_train_21)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train_21, y_train_pred_21)\n",
    "print(f\"Random Forest Model accuracy on train_data: {train_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "Train set accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "#RF model 22 Training\n",
    "# set warm_start and increase num of estimators\n",
    "rf_model.set_params(warm_start=True, n_estimators=rf_model.n_estimators + 50)  # Add 50 more trees\n",
    "rf_model.fit(X_train_22, y_train_22) # fit additional 10 trees\n",
    "print(len(rf_model.estimators_)) # Print the number of trees\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_22 = rf_model.predict(X_train_22)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_22 = accuracy_score(y_train_22, y_train_pred_22)\n",
    "print(f\"Train set accuracy: {train_accuracy_22:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Train set accuracy after retraining with 2023 data: 0.89\n"
     ]
    }
   ],
   "source": [
    "#RF model 23 Training\n",
    "# Update the Random Forest model for warm start\n",
    "rf_model.set_params(warm_start=True, n_estimators=rf_model.n_estimators + 50)  # Add 50 more trees\n",
    "rf_model.fit(X_train_23, y_train_23)\n",
    "print(len(rf_model.estimators_)) # Print the number of trees\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_23 = rf_model.predict(X_train_23)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_2023 = accuracy_score(y_train_23, y_train_pred_23)\n",
    "print(f\"Train set accuracy after retraining with 2023 data: {train_accuracy_2023:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "Train set accuracy after retraining with 2024 data: 0.94\n"
     ]
    }
   ],
   "source": [
    "#RF model 24 Training\n",
    "# Update the Random Forest model for warm start\n",
    "rf_model.set_params(warm_start=True, n_estimators=rf_model.n_estimators + 50)  # Add 50 more trees\n",
    "rf_model.fit(X_train_24, y_train_24)\n",
    "print(len(rf_model.estimators_)) # Print the number of trees\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_24 = rf_model.predict(X_train_24)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_2024 = accuracy_score(y_train_24, y_train_pred_24)\n",
    "print(f\"Train set accuracy after retraining with 2024 data: {train_accuracy_2024:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_model = LogisticRegression(random_state=42)\n",
    "log_reg_model.fit(X_train_21, y_train_21)\n",
    "\n",
    "print(\"Model trained successfully.\")\n",
    "\n",
    "# Predict on training data\n",
    "y_train_pred_21 = log_reg_model.predict(X_train_21)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train_21, y_train_pred_21)\n",
    "print(f\"Random Forest Model accuracy on train_data: {train_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for Logistic Regression (2022): 0.81\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model for 2022 Training with warm start\n",
    "log_reg_model.set_params(max_iter=200, warm_start=True)  # Enable warm start and update max_iter if needed\n",
    "log_reg_model.fit(X_train_22, y_train_22)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_22 = log_reg_model.predict(X_train_22)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_22 = accuracy_score(y_train_22, y_train_pred_22)\n",
    "print(f\"Train set accuracy for Logistic Regression (2022): {train_accuracy_22:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for Logistic Regression (2023): 0.79\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model for 2022 Training with warm start\n",
    "log_reg_model.set_params(max_iter=200, warm_start=True)  # Enable warm start and update max_iter if needed\n",
    "log_reg_model.fit(X_train_23, y_train_23)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_23 = log_reg_model.predict(X_train_23)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_23 = accuracy_score(y_train_23, y_train_pred_23)\n",
    "print(f\"Train set accuracy for Logistic Regression (2023): {train_accuracy_23:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for Logistic Regression (2024): 0.81\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model for 2022 Training with warm start\n",
    "log_reg_model.set_params(max_iter=200, warm_start=True)  # Enable warm start and update max_iter if needed\n",
    "log_reg_model.fit(X_train_24, y_train_24)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_24 = log_reg_model.predict(X_train_24)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_24 = accuracy_score(y_train_24, y_train_pred_24)\n",
    "print(f\"Train set accuracy for Logistic Regression (2024): {train_accuracy_22:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for HGB Classifier (2021): 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "model = HistGradientBoostingClassifier(\n",
    "    max_iter=100,  # Number of trees\n",
    "    learning_rate=0.1,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=20,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_21, y_train_21)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_21 = model.predict(X_train_21)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_21 = accuracy_score(y_train_21, y_train_pred_21)\n",
    "print(f\"Train set accuracy for HGB Classifier (2021): {train_accuracy_22:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for HGB Classifier (2022): 0.99\n"
     ]
    }
   ],
   "source": [
    "# Histogram Gradient Boosting model for 2022 Training with warm start\n",
    "model.set_params(warm_start=True, max_iter=model.max_iter + 100)  # Increment iterations\n",
    "model.fit(X_train_22, y_train_22)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_22 = model.predict(X_train_22)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_22 = accuracy_score(y_train_22, y_train_pred_22)\n",
    "print(f\"Train set accuracy for HGB Classifier (2022): {train_accuracy_22:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for HGB Classifier (2023): 0.97\n"
     ]
    }
   ],
   "source": [
    "# Histogram Gradient Boosting model for 2023 Training with warm start\n",
    "model.set_params(warm_start=True, max_iter=model.max_iter + 100)  # Increment iterations\n",
    "model.fit(X_train_23, y_train_23)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_23 = model.predict(X_train_23)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_23 = accuracy_score(y_train_23, y_train_pred_23)\n",
    "print(f\"Train set accuracy for HGB Classifier (2023): {train_accuracy_23:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for HGB Classifier (2024): 0.96\n"
     ]
    }
   ],
   "source": [
    "# Histogram Gradient Boosting model for 2024 Training with warm start\n",
    "model.set_params(warm_start=True, max_iter=model.max_iter + 100)  # Increment iterations\n",
    "model.fit(X_train_24, y_train_24)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_24 = model.predict(X_train_24)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_24 = accuracy_score(y_train_24, y_train_pred_24)\n",
    "print(f\"Train set accuracy for HGB Classifier (2024): {train_accuracy_24:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for passive aggressive classifier (2021): 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "pa_classifier = PassiveAggressiveClassifier(C=1.0, max_iter=1000, random_state=42)\n",
    "pa_classifier.fit(X_train_21, y_train_21)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_21 = model.predict(X_train_21)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_21 = accuracy_score(y_train_21, y_train_pred_21)\n",
    "print(f\"Train set accuracy for passive aggressive classifier (2021): {train_accuracy_21:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for Passive Aggressive Classifier (2022): 0.78\n"
     ]
    }
   ],
   "source": [
    "# Passive Aggressive Classifier for 2022 Training with warm start\n",
    "pa_classifier.set_params(max_iter=pa_classifier.max_iter + 100, warm_start=True)  # Enable warm start and add iterations\n",
    "pa_classifier.fit(X_train_22, y_train_22)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_22 = pa_classifier.predict(X_train_22)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_22 = accuracy_score(y_train_22, y_train_pred_22)\n",
    "print(f\"Train set accuracy for Passive Aggressive Classifier (2022): {train_accuracy_22:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for Passive Aggressive Classifier (2023): 0.75\n"
     ]
    }
   ],
   "source": [
    "# Passive Aggressive Classifier for 2023 Training with warm start\n",
    "pa_classifier.set_params(max_iter=pa_classifier.max_iter + 100, warm_start=True)  # Enable warm start and add iterations\n",
    "pa_classifier.fit(X_train_23, y_train_23)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_23 = pa_classifier.predict(X_train_23)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_23 = accuracy_score(y_train_23, y_train_pred_23)\n",
    "print(f\"Train set accuracy for Passive Aggressive Classifier (2023): {train_accuracy_23:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy for Passive Aggressive Classifier (2024): 0.54\n"
     ]
    }
   ],
   "source": [
    "# Passive Aggressive Classifier for 2024 Training with warm start\n",
    "pa_classifier.set_params(max_iter=pa_classifier.max_iter + 100, warm_start=True)  # Enable warm start and add iterations\n",
    "pa_classifier.fit(X_train_24, y_train_24)\n",
    "\n",
    "# Predict on the train set\n",
    "y_train_pred_24 = pa_classifier.predict(X_train_24)\n",
    "\n",
    "# Calculate accuracy on the train set\n",
    "train_accuracy_24 = accuracy_score(y_train_24, y_train_pred_24)\n",
    "print(f\"Train set accuracy for Passive Aggressive Classifier (2024): {train_accuracy_24:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model brier score loss on 2021 test_data: 0.11\n",
      "F1 Score for RF model: 0.93\n",
      "Logistic Regression model brier score loss on 2021 test_data: 0.25\n",
      "F1 Score for Logistic Regression model: 0.85\n",
      "HGB model brier score loss on 2021 test_data: 0.15\n",
      "F1 Score for HGB model: 0.90\n",
      "Passive Aggressive model brier score loss on 2021 test_data: 0.41\n",
      "F1 Score for Passive Aggressive model: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2021 test data\n",
    "y_test_pred_rf_21 = rf_model.predict(test_data_21[features])\n",
    "y_test_pred_log_reg_21 = log_reg_model.predict(test_data_21[features])\n",
    "y_test_pred_hgb_21 = model.predict(test_data_21[features])\n",
    "y_test_pred_pa_21 = pa_classifier.predict(test_data_21[features])\n",
    "\n",
    "# Calculate accuracy on 2021 test data\n",
    "test_accuracy = brier_score_loss(test_data_21['Outcome'], y_test_pred_rf_21) #Assess RF\n",
    "f1_score_rf = f1_score(test_data_21['Outcome'], y_test_pred_rf_21)\n",
    "print(f\"RF model brier score loss on 2021 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for RF model: {f1_score_rf:.2f}\")\n",
    "test_accuracy = brier_score_loss(test_data_21['Outcome'], y_test_pred_log_reg_21) #Assess Logistic Regression\n",
    "f1_score_log_reg = f1_score(test_data_21['Outcome'], y_test_pred_log_reg_21)\n",
    "print(f\"Logistic Regression model brier score loss on 2021 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for Logistic Regression model: {f1_score_log_reg:.2f}\")\n",
    "test_accuracy = brier_score_loss(test_data_21['Outcome'], y_test_pred_hgb_21) #Assess HGB\n",
    "f1_score_hgb = f1_score(test_data_21['Outcome'], y_test_pred_hgb_21)\n",
    "print(f\"HGB model brier score loss on 2021 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for HGB model: {f1_score_hgb:.2f}\")\n",
    "test_accuracy = brier_score_loss(test_data_21['Outcome'], y_test_pred_pa_21) #Assess Passive Aggressive\n",
    "f1_score_pa = f1_score(test_data_21['Outcome'], y_test_pred_pa_21)\n",
    "print(f\"Passive Aggressive model brier score loss on 2021 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for Passive Aggressive model: {f1_score_pa:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model brier score loss on 2022 test_data: 0.20\n",
      "F1 Score for RF model: 0.88\n",
      "Logistic Regression model brier score loss on 2022 test_data: 0.23\n",
      "F1 Score for Logistic Regression model: 0.87\n",
      "HGB model brier score loss on 2022 test_data: 0.22\n",
      "F1 Score for HGB model: 0.86\n",
      "Passive Aggressive model brier score loss on 2022 test_data: 0.49\n",
      "F1 Score for Passive Aggressive model: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2022 test data\n",
    "y_test_pred_rf_22 = rf_model.predict(test_data_22[features])\n",
    "y_test_pred_log_reg_22 = log_reg_model.predict(test_data_22[features])\n",
    "y_test_pred_hgb_22 = model.predict(test_data_22[features])\n",
    "y_test_pred_pa_22 = pa_classifier.predict(test_data_22[features])\n",
    "\n",
    "# Calculate accuracy on 2022 test data\n",
    "test_accuracy = brier_score_loss(test_data_22['Outcome'], y_test_pred_rf_22)  # Assess RF\n",
    "f1_score_rf = f1_score(test_data_22['Outcome'], y_test_pred_rf_22)\n",
    "print(f\"RF model brier score loss on 2022 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for RF model: {f1_score_rf:.2f}\")\n",
    "\n",
    "test_accuracy = brier_score_loss(test_data_22['Outcome'], y_test_pred_log_reg_22)  # Assess Logistic Regression\n",
    "f1_score_log_reg = f1_score(test_data_22['Outcome'], y_test_pred_log_reg_22)\n",
    "print(f\"Logistic Regression model brier score loss on 2022 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for Logistic Regression model: {f1_score_log_reg:.2f}\")\n",
    "\n",
    "test_accuracy = brier_score_loss(test_data_22['Outcome'], y_test_pred_hgb_22)  # Assess HGB\n",
    "f1_score_hgb = f1_score(test_data_22['Outcome'], y_test_pred_hgb_22)\n",
    "print(f\"HGB model brier score loss on 2022 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for HGB model: {f1_score_hgb:.2f}\")\n",
    "\n",
    "test_accuracy = brier_score_loss(test_data_22['Outcome'], y_test_pred_pa_22)  # Assess Passive Aggressive\n",
    "f1_score_pa = f1_score(test_data_22['Outcome'], y_test_pred_pa_22)\n",
    "print(f\"Passive Aggressive model brier score loss on 2022 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for Passive Aggressive model: {f1_score_pa:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model brier score loss on 2023 test_data: 0.20\n",
      "F1 Score for RF model: 0.88\n",
      "Logistic Regression model brier score loss on 2023 test_data: 0.22\n",
      "F1 Score for Logistic Regression model: 0.87\n",
      "HGB model brier score loss on 2023 test_data: 0.19\n",
      "F1 Score for HGB model: 0.88\n",
      "Passive Aggressive model brier score loss on 2023 test_data: 0.50\n",
      "F1 Score for Passive Aggressive model: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2023 test data\n",
    "y_test_pred_rf_23 = rf_model.predict(test_data_23[features])\n",
    "y_test_pred_log_reg_23 = log_reg_model.predict(test_data_23[features])\n",
    "y_test_pred_hgb_23 = model.predict(test_data_23[features])\n",
    "y_test_pred_pa_23 = pa_classifier.predict(test_data_23[features])\n",
    "\n",
    "# Calculate accuracy on 2023 test data\n",
    "test_accuracy = brier_score_loss(test_data_23['Outcome'], y_test_pred_rf_23)  # Assess RF\n",
    "f1_score_rf = f1_score(test_data_23['Outcome'], y_test_pred_rf_23)\n",
    "print(f\"RF model brier score loss on 2023 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for RF model: {f1_score_rf:.2f}\")\n",
    "\n",
    "test_accuracy = brier_score_loss(test_data_23['Outcome'], y_test_pred_log_reg_23)  # Assess Logistic Regression\n",
    "f1_score_log_reg = f1_score(test_data_23['Outcome'], y_test_pred_log_reg_23)\n",
    "print(f\"Logistic Regression model brier score loss on 2023 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for Logistic Regression model: {f1_score_log_reg:.2f}\")\n",
    "\n",
    "test_accuracy = brier_score_loss(test_data_23['Outcome'], y_test_pred_hgb_23)  # Assess HGB\n",
    "f1_score_hgb = f1_score(test_data_23['Outcome'], y_test_pred_hgb_23)\n",
    "print(f\"HGB model brier score loss on 2023 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for HGB model: {f1_score_hgb:.2f}\")\n",
    "\n",
    "test_accuracy = brier_score_loss(test_data_23['Outcome'], y_test_pred_pa_23)  # Assess Passive Aggressive\n",
    "f1_score_pa = f1_score(test_data_23['Outcome'], y_test_pred_pa_23)\n",
    "print(f\"Passive Aggressive model brier score loss on 2023 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for Passive Aggressive model: {f1_score_pa:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model brier score loss on 2024 test_data: 0.19\n",
      "F1 Score for RF model: 0.89\n",
      "Logistic Regression model brier score loss on 2024 test_data: 0.23\n",
      "F1 Score for Logistic Regression model: 0.87\n",
      "HGB model brier score loss on 2024 test_data: 0.22\n",
      "F1 Score for HGB model: 0.86\n",
      "Passive Aggressive model brier score loss on 2024 test_data: 0.45\n",
      "F1 Score for Passive Aggressive model: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Predict on 2024 test data\n",
    "y_test_pred_rf_24 = rf_model.predict(test_data_24[features])\n",
    "y_test_pred_log_reg_24 = log_reg_model.predict(test_data_24[features])\n",
    "y_test_pred_hgb_24 = model.predict(test_data_24[features])\n",
    "y_test_pred_pa_24 = pa_classifier.predict(test_data_24[features])\n",
    "\n",
    "# Calculate accuracy on 2024 test data\n",
    "test_accuracy = brier_score_loss(test_data_24['Outcome'], y_test_pred_rf_24)  # Assess RF\n",
    "f1_score_rf = f1_score(test_data_24['Outcome'], y_test_pred_rf_24)\n",
    "print(f\"RF model brier score loss on 2024 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for RF model: {f1_score_rf:.2f}\")\n",
    "\n",
    "test_accuracy = brier_score_loss(test_data_24['Outcome'], y_test_pred_log_reg_24)  # Assess Logistic Regression\n",
    "f1_score_log_reg = f1_score(test_data_24['Outcome'], y_test_pred_log_reg_24)\n",
    "print(f\"Logistic Regression model brier score loss on 2024 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for Logistic Regression model: {f1_score_log_reg:.2f}\")\n",
    "\n",
    "test_accuracy = brier_score_loss(test_data_24['Outcome'], y_test_pred_hgb_24)  # Assess HGB\n",
    "f1_score_hgb = f1_score(test_data_24['Outcome'], y_test_pred_hgb_24)\n",
    "print(f\"HGB model brier score loss on 2024 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for HGB model: {f1_score_hgb:.2f}\")\n",
    "\n",
    "test_accuracy = brier_score_loss(test_data_24['Outcome'], y_test_pred_pa_24)  # Assess Passive Aggressive\n",
    "f1_score_pa = f1_score(test_data_24['Outcome'], y_test_pred_pa_24)\n",
    "print(f\"Passive Aggressive model brier score loss on 2024 test_data: {test_accuracy:.2f}\")\n",
    "print(f\"F1 Score for Passive Aggressive model: {f1_score_pa:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Stage 1 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ModelInput tables with SampleSubmissionStage1 based on Team1 and Team2\n",
    "merged_data_2021 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2021]\n",
    "merged_data_2021 = merged_data_2021.merge(ModelInput21.add_suffix('_Team1'), left_on='Team1', right_on='TeamID_Team1', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_2021 = merged_data_2021.merge(ModelInput21.add_suffix('_Team2'), left_on='Team2', right_on='TeamID_Team2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_2022 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2022]\n",
    "merged_data_2022 = merged_data_2022.merge(ModelInput22.add_suffix('_Team1'), left_on='Team1', right_on='TeamID_Team1', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_2022 = merged_data_2022.merge(ModelInput22.add_suffix('_Team2'), left_on='Team2', right_on='TeamID_Team2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_2023 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2023]\n",
    "merged_data_2023 = merged_data_2023.merge(ModelInput23.add_suffix('_Team1'), left_on='Team1', right_on='TeamID_Team1', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_2023 = merged_data_2023.merge(ModelInput23.add_suffix('_Team2'), left_on='Team2', right_on='TeamID_Team2', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_2024 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2024]\n",
    "merged_data_2024 = merged_data_2024.merge(ModelInput24.add_suffix('_Team1'), left_on='Team1', right_on='TeamID_Team1', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_2024 = merged_data_2024.merge(ModelInput24.add_suffix('_Team2'), left_on='Team2', right_on='TeamID_Team2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ModelInput tables with SampleSubmissionStage1 based on Team1 and Team2\n",
    "merged_data_2021 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2021]\n",
    "merged_data_2021 = merged_data_2021.merge(ModelInput21.add_suffix('_Team1'), left_on='Team1', right_on='TeamID_Team1', how='left')\n",
    "merged_data_2021 = merged_data_2021.merge(ModelInput21.add_suffix('_Team2'), left_on='Team2', right_on='TeamID_Team2', how='left')\n",
    "\n",
    "merged_data_2022 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2022]\n",
    "merged_data_2022 = merged_data_2022.merge(ModelInput22.add_suffix('_Team1'), left_on='Team1', right_on='TeamID_Team1', how='left')\n",
    "merged_data_2022 = merged_data_2022.merge(ModelInput22.add_suffix('_Team2'), left_on='Team2', right_on='TeamID_Team2', how='left')\n",
    "\n",
    "merged_data_2023 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2023]\n",
    "merged_data_2023 = merged_data_2023.merge(ModelInput23.add_suffix('_Team1'), left_on='Team1', right_on='TeamID_Team1', how='left')\n",
    "merged_data_2023 = merged_data_2023.merge(ModelInput23.add_suffix('_Team2'), left_on='Team2', right_on='TeamID_Team2', how='left')\n",
    "\n",
    "merged_data_2024 = SampleSubmissionStage1[SampleSubmissionStage1['Season'] == 2024]\n",
    "merged_data_2024 = merged_data_2024.merge(ModelInput24.add_suffix('_Team1'), left_on='Team1', right_on='TeamID_Team1', how='left')\n",
    "merged_data_2024 = merged_data_2024.merge(ModelInput24.add_suffix('_Team2'), left_on='Team2', right_on='TeamID_Team2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_all = pd.concat([merged_data_2021, merged_data_2022, merged_data_2023, merged_data_2024], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_3101_3102</td>\n",
       "      <td>0.656667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021_3101_3103</td>\n",
       "      <td>0.703333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021_3101_3104</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021_3101_3105</td>\n",
       "      <td>0.536667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021_3101_3106</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      Pred\n",
       "0  2021_3101_3102  0.656667\n",
       "1  2021_3101_3103  0.703333\n",
       "2  2021_3101_3104  0.520000\n",
       "3  2021_3101_3105  0.536667\n",
       "4  2021_3101_3106  0.480000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the features used for training are present in merged_data_all\n",
    "features = ['Wins_Team1', 'avg_score_diff_Team1', 'FG_PCT_Team1', 'FG3_PCT_Team1', 'FT_PCT_Team1', \n",
    "            'REB_Team1', 'AST_Team1', 'TO_Team1', 'STL_Team1', 'BLK_Team1', 'PF_Team1', \n",
    "            'Wins_Team2', 'avg_score_diff_Team2', 'FG_PCT_Team2', 'FG3_PCT_Team2', 'FT_PCT_Team2', \n",
    "            'REB_Team2', 'AST_Team2', 'TO_Team2', 'STL_Team2', 'BLK_Team2', 'PF_Team2']\n",
    "\n",
    "# Make predictions\n",
    "merged_data_all['Pred'] = rf_model.predict_proba(merged_data_all[features])[:, 1]\n",
    "\n",
    "# Display the first few rows of the predictions\n",
    "merged_data_all[['ID', 'Pred']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_all[['ID', 'Pred']].to_csv('womens_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_all.to_csv(\"WPred_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelInput25 = pd.DataFrame(WTeams['TeamID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelInput25['Wins'] = ModelInput25['TeamID'].apply(lambda x: record_record(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2025]))\n",
    "ModelInput25['avg_score_diff'] = ModelInput25['TeamID'].apply(lambda x: avg_score_difference(x, WRegularSeasonCompactResults[WRegularSeasonCompactResults['Season'] == 2025]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = ModelInput25['TeamID'].apply(lambda x: team_stats_differences(x, WRegularSeasonDetailedResults[WRegularSeasonDetailedResults['Season'] == 2025]))\n",
    "team_stats_df = pd.DataFrame(team_stats.tolist(), columns=['FG_PCT', 'FG3_PCT', 'FT_PCT', 'REB', 'AST', 'TO', 'STL', 'BLK', 'PF'])\n",
    "ModelInput25 = pd.concat([ModelInput25, team_stats_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSubmissionStage2 = pd.read_csv('SampleSubmissionStage2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Stage 2\n",
    "SampleSubmissionStage2['Season'] = SampleSubmissionStage2['ID'].apply(lambda x: int(x.split('_')[0]))\n",
    "SampleSubmissionStage2['Team1'] = SampleSubmissionStage2['ID'].apply(lambda x: int(x.split('_')[1]))\n",
    "SampleSubmissionStage2['Team2'] = SampleSubmissionStage2['ID'].apply(lambda x: int(x.split('_')[2]))\n",
    "SampleSubmissionStage2 = SampleSubmissionStage2[SampleSubmissionStage2['Team1'].astype(str).str.startswith('3') & SampleSubmissionStage2['Team2'].astype(str).str.startswith('3')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with ModelInput25 for Team1 and Team2\n",
    "SampleSubmissionStage2 = SampleSubmissionStage2.merge(ModelInput25.add_suffix('_Team1'), left_on='Team1', right_on='TeamID_Team1', how='left')\n",
    "SampleSubmissionStage2 = SampleSubmissionStage2.merge(ModelInput25.add_suffix('_Team2'), left_on='Team2', right_on='TeamID_Team2', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>TeamID_Team1</th>\n",
       "      <th>Wins_Team1</th>\n",
       "      <th>avg_score_diff_Team1</th>\n",
       "      <th>FG_PCT_Team1</th>\n",
       "      <th>FG3_PCT_Team1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_score_diff_Team2</th>\n",
       "      <th>FG_PCT_Team2</th>\n",
       "      <th>FG3_PCT_Team2</th>\n",
       "      <th>FT_PCT_Team2</th>\n",
       "      <th>REB_Team2</th>\n",
       "      <th>AST_Team2</th>\n",
       "      <th>TO_Team2</th>\n",
       "      <th>STL_Team2</th>\n",
       "      <th>BLK_Team2</th>\n",
       "      <th>PF_Team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65336</th>\n",
       "      <td>2025_3477_3479</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2025</td>\n",
       "      <td>3477</td>\n",
       "      <td>3479</td>\n",
       "      <td>3477</td>\n",
       "      <td>5</td>\n",
       "      <td>-11.296296</td>\n",
       "      <td>-0.043140</td>\n",
       "      <td>0.031054</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.708333</td>\n",
       "      <td>-0.038620</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>0.023294</td>\n",
       "      <td>-5.083333</td>\n",
       "      <td>-1.916667</td>\n",
       "      <td>2.458333</td>\n",
       "      <td>-3.208333</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65337</th>\n",
       "      <td>2025_3477_3480</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2025</td>\n",
       "      <td>3477</td>\n",
       "      <td>3480</td>\n",
       "      <td>3477</td>\n",
       "      <td>5</td>\n",
       "      <td>-11.296296</td>\n",
       "      <td>-0.043140</td>\n",
       "      <td>0.031054</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.285714</td>\n",
       "      <td>-0.029374</td>\n",
       "      <td>-0.015804</td>\n",
       "      <td>-0.040822</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>-0.321429</td>\n",
       "      <td>2.392857</td>\n",
       "      <td>-0.357143</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65338</th>\n",
       "      <td>2025_3478_3479</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2025</td>\n",
       "      <td>3478</td>\n",
       "      <td>3479</td>\n",
       "      <td>3478</td>\n",
       "      <td>7</td>\n",
       "      <td>-15.096774</td>\n",
       "      <td>-0.080031</td>\n",
       "      <td>-0.019995</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.708333</td>\n",
       "      <td>-0.038620</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>0.023294</td>\n",
       "      <td>-5.083333</td>\n",
       "      <td>-1.916667</td>\n",
       "      <td>2.458333</td>\n",
       "      <td>-3.208333</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65339</th>\n",
       "      <td>2025_3478_3480</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2025</td>\n",
       "      <td>3478</td>\n",
       "      <td>3480</td>\n",
       "      <td>3478</td>\n",
       "      <td>7</td>\n",
       "      <td>-15.096774</td>\n",
       "      <td>-0.080031</td>\n",
       "      <td>-0.019995</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.285714</td>\n",
       "      <td>-0.029374</td>\n",
       "      <td>-0.015804</td>\n",
       "      <td>-0.040822</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>-0.321429</td>\n",
       "      <td>2.392857</td>\n",
       "      <td>-0.357143</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65340</th>\n",
       "      <td>2025_3479_3480</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2025</td>\n",
       "      <td>3479</td>\n",
       "      <td>3480</td>\n",
       "      <td>3479</td>\n",
       "      <td>6</td>\n",
       "      <td>-7.708333</td>\n",
       "      <td>-0.038620</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.285714</td>\n",
       "      <td>-0.029374</td>\n",
       "      <td>-0.015804</td>\n",
       "      <td>-0.040822</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>-0.321429</td>\n",
       "      <td>2.392857</td>\n",
       "      <td>-0.357143</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-0.928571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  Pred  Season  Team1  Team2  TeamID_Team1  Wins_Team1  \\\n",
       "65336  2025_3477_3479   0.5    2025   3477   3479          3477           5   \n",
       "65337  2025_3477_3480   0.5    2025   3477   3480          3477           5   \n",
       "65338  2025_3478_3479   0.5    2025   3478   3479          3478           7   \n",
       "65339  2025_3478_3480   0.5    2025   3478   3480          3478           7   \n",
       "65340  2025_3479_3480   0.5    2025   3479   3480          3479           6   \n",
       "\n",
       "       avg_score_diff_Team1  FG_PCT_Team1  FG3_PCT_Team1  ...  \\\n",
       "65336            -11.296296     -0.043140       0.031054  ...   \n",
       "65337            -11.296296     -0.043140       0.031054  ...   \n",
       "65338            -15.096774     -0.080031      -0.019995  ...   \n",
       "65339            -15.096774     -0.080031      -0.019995  ...   \n",
       "65340             -7.708333     -0.038620       0.041574  ...   \n",
       "\n",
       "       avg_score_diff_Team2  FG_PCT_Team2  FG3_PCT_Team2  FT_PCT_Team2  \\\n",
       "65336             -7.708333     -0.038620       0.041574      0.023294   \n",
       "65337             -5.285714     -0.029374      -0.015804     -0.040822   \n",
       "65338             -7.708333     -0.038620       0.041574      0.023294   \n",
       "65339             -5.285714     -0.029374      -0.015804     -0.040822   \n",
       "65340             -5.285714     -0.029374      -0.015804     -0.040822   \n",
       "\n",
       "       REB_Team2  AST_Team2  TO_Team2  STL_Team2  BLK_Team2  PF_Team2  \n",
       "65336  -5.083333  -1.916667  2.458333  -3.208333  -1.166667 -0.958333  \n",
       "65337   1.214286  -0.321429  2.392857  -0.357143  -0.714286 -0.928571  \n",
       "65338  -5.083333  -1.916667  2.458333  -3.208333  -1.166667 -0.958333  \n",
       "65339   1.214286  -0.321429  2.392857  -0.357143  -0.714286 -0.928571  \n",
       "65340   1.214286  -0.321429  2.392857  -0.357143  -0.714286 -0.928571  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SampleSubmissionStage2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "SampleSubmissionStage2['Pred'] = rf_model.predict_proba(SampleSubmissionStage2[features])[:, 1]\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "SampleSubmissionStage2[['ID', 'Pred']].to_csv('womens_submission_stage2.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the predictions\n",
    "SampleSubmissionStage2[['ID', 'Pred']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Team1_Name</th>\n",
       "      <th>Team2_Name</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025_3101_3102</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025_3101_3103</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Akron</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025_3101_3104</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0.473333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025_3101_3105</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025_3101_3106</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>Alabama St</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID   Team1_Name   Team2_Name      Pred\n",
       "0  2025_3101_3102  Abilene Chr    Air Force  0.640000\n",
       "1  2025_3101_3103  Abilene Chr        Akron  0.910000\n",
       "2  2025_3101_3104  Abilene Chr      Alabama  0.473333\n",
       "3  2025_3101_3105  Abilene Chr  Alabama A&M  0.516667\n",
       "4  2025_3101_3106  Abilene Chr   Alabama St  0.933333"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add predictions from SampleSubmissionStage2 to the main dataset\n",
    "SampleResults = SampleSubmissionStage2.merge(WTeams[['TeamID', 'TeamName']], left_on='Team1', right_on='TeamID', how='left').rename(columns={'TeamName': 'Team1_Name'})\n",
    "SampleResults = SampleResults.merge(WTeams[['TeamID', 'TeamName']], left_on='Team2', right_on='TeamID', how='left').rename(columns={'TeamName': 'Team2_Name'})\n",
    "\n",
    "# Select relevant columns and display the predictions\n",
    "SampleResults[['ID', 'Team1_Name', 'Team2_Name', 'Pred']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Pred</th>\n",
       "      <th>Season</th>\n",
       "      <th>Team1</th>\n",
       "      <th>Team2</th>\n",
       "      <th>TeamID_Team1</th>\n",
       "      <th>Wins_Team1</th>\n",
       "      <th>avg_score_diff_Team1</th>\n",
       "      <th>FG_PCT_Team1</th>\n",
       "      <th>FG3_PCT_Team1</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_score_diff_Team2</th>\n",
       "      <th>FG_PCT_Team2</th>\n",
       "      <th>FG3_PCT_Team2</th>\n",
       "      <th>FT_PCT_Team2</th>\n",
       "      <th>REB_Team2</th>\n",
       "      <th>AST_Team2</th>\n",
       "      <th>TO_Team2</th>\n",
       "      <th>STL_Team2</th>\n",
       "      <th>BLK_Team2</th>\n",
       "      <th>PF_Team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025_3101_3102</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3102</td>\n",
       "      <td>3101</td>\n",
       "      <td>17</td>\n",
       "      <td>4.310345</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>...</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>-0.043636</td>\n",
       "      <td>-0.004991</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>-4.733333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>-5.300000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>-1.333333</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025_3101_3103</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3103</td>\n",
       "      <td>3101</td>\n",
       "      <td>17</td>\n",
       "      <td>4.310345</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.689655</td>\n",
       "      <td>-0.045665</td>\n",
       "      <td>-0.066817</td>\n",
       "      <td>-0.040376</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>-2.275862</td>\n",
       "      <td>3.448276</td>\n",
       "      <td>-0.965517</td>\n",
       "      <td>-0.413793</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025_3101_3104</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3104</td>\n",
       "      <td>3101</td>\n",
       "      <td>17</td>\n",
       "      <td>4.310345</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>...</td>\n",
       "      <td>15.645161</td>\n",
       "      <td>0.089239</td>\n",
       "      <td>0.119739</td>\n",
       "      <td>-0.028259</td>\n",
       "      <td>3.258065</td>\n",
       "      <td>3.387097</td>\n",
       "      <td>-2.322581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>1.903226</td>\n",
       "      <td>-1.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025_3101_3105</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3105</td>\n",
       "      <td>3101</td>\n",
       "      <td>17</td>\n",
       "      <td>4.310345</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>...</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>-0.011725</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.020367</td>\n",
       "      <td>-3.300000</td>\n",
       "      <td>-2.533333</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>-0.566667</td>\n",
       "      <td>-4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025_3101_3106</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>2025</td>\n",
       "      <td>3101</td>\n",
       "      <td>3106</td>\n",
       "      <td>3101</td>\n",
       "      <td>17</td>\n",
       "      <td>4.310345</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.022957</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.642857</td>\n",
       "      <td>-0.121476</td>\n",
       "      <td>-0.086632</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>-5.357143</td>\n",
       "      <td>-7.285714</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>-4.071429</td>\n",
       "      <td>-0.928571</td>\n",
       "      <td>2.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      Pred  Season  Team1  Team2  TeamID_Team1  Wins_Team1  \\\n",
       "0  2025_3101_3102  0.640000    2025   3101   3102          3101          17   \n",
       "1  2025_3101_3103  0.910000    2025   3101   3103          3101          17   \n",
       "2  2025_3101_3104  0.473333    2025   3101   3104          3101          17   \n",
       "3  2025_3101_3105  0.516667    2025   3101   3105          3101          17   \n",
       "4  2025_3101_3106  0.933333    2025   3101   3106          3101          17   \n",
       "\n",
       "   avg_score_diff_Team1  FG_PCT_Team1  FG3_PCT_Team1  ...  \\\n",
       "0              4.310345     -0.004245      -0.022957  ...   \n",
       "1              4.310345     -0.004245      -0.022957  ...   \n",
       "2              4.310345     -0.004245      -0.022957  ...   \n",
       "3              4.310345     -0.004245      -0.022957  ...   \n",
       "4              4.310345     -0.004245      -0.022957  ...   \n",
       "\n",
       "   avg_score_diff_Team2  FG_PCT_Team2  FG3_PCT_Team2  FT_PCT_Team2  REB_Team2  \\\n",
       "0              1.533333     -0.043636      -0.004991      0.021159  -4.733333   \n",
       "1             -7.689655     -0.045665      -0.066817     -0.040376   3.448276   \n",
       "2             15.645161      0.089239       0.119739     -0.028259   3.258065   \n",
       "3              3.200000     -0.011725       0.002150      0.020367  -3.300000   \n",
       "4            -23.642857     -0.121476      -0.086632      0.025751  -5.357143   \n",
       "\n",
       "   AST_Team2  TO_Team2  STL_Team2  BLK_Team2  PF_Team2  \n",
       "0   0.233333 -5.300000   3.200000  -1.333333  1.100000  \n",
       "1  -2.275862  3.448276  -0.965517  -0.413793  0.482759  \n",
       "2   3.387097 -2.322581   0.870968   1.903226 -1.225806  \n",
       "3  -2.533333 -3.666667   2.933333  -0.566667 -4.200000  \n",
       "4  -7.285714  4.571429  -4.071429  -0.928571  2.142857  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SampleSubmissionStage2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
